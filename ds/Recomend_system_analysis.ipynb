{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Задача:\n",
    "Нам надо предсказывать соавторов для определенного автора.\n",
    "Из публикаций для каждого автора мы знаем его настоящих соавторов, эти данные можно использовать для обучения.\n",
    "\n",
    "Варианты разбиения:\n",
    "\n",
    "Информацию брал отсюда: https://arxiv.org/pdf/2007.13237.pdf\n",
    "\n",
    "**Leave One Last**\n",
    "<p>Для каждого автора берем его последнюю публикацию (его соавторов) и оставляем на тест, предпоследнюю публикацию оставляем на валидацию, остальные публикации - трейн.</p>\n",
    "<p>Плюсы:</p>\n",
    "\n",
    "* Используется максимум датасета для тренировки\n",
    "\n",
    "<p>Минусы:</p>\n",
    "\n",
    "* Возможен лик, так как одна и та же статься для одного автора может быть в трейне, а для другого в тесте.\n",
    "* Тестовый датасет включает только одну запись для пользователя - мы не можем отследить динамику нашей рекомендательной системы по времени на тестовых данных.\n",
    "\n",
    "**Temporal User Split**\n",
    "<p>Схожа с Leave One Last, только для каждого автора берем какой-то фиксированный процент его последних публикаций и оставляем на тест/валидацию, остальные публикации - трейн.</p>\n",
    "\n",
    "Плюсы и минусы схожи с Leave One Last методом. Здесь уже можем посмотреть динамику, однако пять же может быт лик.\n",
    "\n",
    "**Temporal Global Split**\n",
    "<p>Выбираем какой-нибудь год как барьер: все статьи до него - треин, после - тест.</p>\n",
    "\n",
    "Плюсы:\n",
    "* Нет даталика, не смотрим в будущее;\n",
    "* довольно просто разделять;\n",
    "\n",
    "Минусы:\n",
    "* Можем не ухватить какой-то новый тренд в науке, который появился недавно, так как его не будет в train. Или что в трейне было актуально, теперь в тесте уже не актуально.\n",
    "\n",
    "**Random Split**\n",
    "<p>Для каждого автора рандомо выбираем барьер, статьи до него - трейн, после него - тест.</p>\n",
    "\n",
    "Минусы:\n",
    "* В нашем случае будет даталик по аналогии с Leave One Last методом.\n",
    "\n",
    "**User Split**\n",
    "<p>Разделить выборку по авторам. То есть какие-то авторы только в трейне, а какие-то только в тесте.</p>\n",
    "\n",
    "Плюсы:\n",
    "* Мы охватываем весь временной отрезок в трейне.\n",
    "\n",
    "Минусы:\n",
    "* Сложно реализовать, нужно чтобы у авторов в трейне и в тесте не было общих статей вообще.\n",
    "* Так как и трейн, и тест находятся в одних временных промежутках, у нас есть статьи в трейне, которые опубликованы позже, чем некоторые статьи в тесте, из-за этого у нас модель заглядывает в будущее и принимает решения, зная о последних трендах.\n",
    "\n",
    "**Выводы**\n",
    "<p>Из предложенных выше методов у нас нет лика только в Temporal Global Split, при этом его еще довольно просто реализовать. Мне кажется, что в качестве бейзлайна можнов выбрать его. Но если вдруг в выборке много важных статей опубликованы недавно, и нам важно захватить их в трейн, то можно попробовать еще User Split метод.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Metrics\n",
    "\n",
    "## Classification metrics\n",
    "\n",
    "Материал: https://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html\n",
    "\n",
    "**Precision, Racall, F1**\n",
    "<p>Выбираются топ-N предсказаний рекомендательной системы и на этом наборе расчитываются данные метрики.\n",
    "\n",
    "Плюсы:\n",
    "* Простота и понятность метрик.\n",
    "\n",
    "Минусы:\n",
    "* Данные метрики не учитывают порядок рекомендованных соавторов в топ-N предсказаний.\n",
    "\n",
    "## Ranking-based metrics\n",
    "\n",
    "**Average precision (AP)**\n",
    "Здесь уже рассматривается среднее между разными precision, каждое из которых берется по топ $k$ пердсказний, где $k$ берется от 1 до $N$, $m$ -- истинное количество соавторов у его авторов.\n",
    "\n",
    "$$\n",
    "AP_N = \\frac{1}{\\min(m, N)} \\sum_{k=1}^N (P(k) \\text { if } k^{t h} \\text { item was relevant }) =\\frac{1}{\\min(m, N)} \\sum_{k=1}^N P(k) \\cdot rel(k)\n",
    "$$\n",
    "\n",
    "Плюсы:\n",
    "* Метика учитывает порядок авторов в рекомендациях.\n",
    "\n",
    "Минусы:\n",
    "* Данную метрику уже сложнее интерпретировать по сравнению с classification метриками.\n",
    "\n",
    "**Mean average precision (MAP)**\n",
    "Усреднение метрики AP по всем авторам (q).\n",
    "$$\n",
    "\\text { MAP }=\\frac{\\sum_{q=1}^Q \\operatorname{AP}(\\mathrm{q})}{Q}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "269080a76c9cfe9284788914af53192f4bda14a2de38f7424048a09076e613df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
